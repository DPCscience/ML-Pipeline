{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to the ML_Pipeline\n",
    "\n",
    "Here we will walk through how to use scripts in the ML-Pipeline to do machine learning. Check out the [README](https://github.com/ShiuLab/ML-Pipeline/blob/master/README.md) file for a graphical representation of what's going on inside the ML-Pipeline.\n",
    "We are interested in trying to predict grain yield in Zea maize (corn) using information about\n",
    "gene expression levels for 31,237 genes measured on seedlings. We will use these data to \n",
    "predict:\n",
    "- Grain yield for each line (i.e. a regression problem)\n",
    "- If the line was in the top 25% for yield (i.e. a binary classification problem)\n",
    "- If the line was in the top 25%, bottom 25%, or middle 50% for yield (i.e. a multi-class classification problem).\n",
    "\n",
    "\n",
    "### Outline of the tutorial\n",
    "\n",
    "1. Data exploration\n",
    "2. Select instances (i.e. maize lines) to holdout as the final testing set\n",
    "3. Train regression model and apply to testing set\n",
    "4. Train binary classifer and apply to testing set\n",
    "5. Train multi-class classifier and apply to testing set\n",
    "6. Perform feature selection to find the most important features (i.e. genes) for predicting yield\n",
    "7. Apply trained model to instances for which we don't know yield"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "Here we will check out what our data looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_reg = pd.read_csv('data_regression.txt', sep='\\t', index_col = 0)\n",
    "print(d_reg.head())\n",
    "print(d_reg['yield'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_bi = pd.read_csv('data_binary.txt', sep='\\t', index_col = 0)\n",
    "print(d_bi.head())\n",
    "print(d_bi['yield'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_mc = pd.read_csv('data_multiclass.txt', sep='\\t', index_col = 0)\n",
    "print(d_mc.head())\n",
    "print(d_mc['yield'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Select instances (i.e. maize lines) to holdout as the final testing set\n",
    "\n",
    "In order to find out how well our models are performing, we want to set aside some of our\n",
    "data so we can make a final assessment of how well our model performs without any overfitting. \n",
    "\n",
    "The test_set.py script will do this for you! You'll need to provide your dataset (-df), the number (-n) or percent (-p) of instances you would like to set asside for final testing, what to save the output as (-save), and finally, you'll need to specify what type of model you will be running (-type) as either c/r for classification/regression. This is important because while for regression models, testing instances can be selected randomly, for classification models, we might want either the same proportion or the same number of instances from each class. To get the same number of instances from each class use -n, to get a testing set with equal proportions as your training set use -p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holding out 10.0 percent\n",
      "39 instances in holdout\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "%run ../test_set.py -df data_regression.txt -type r -p 0.1 -save test_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ../test_set.py -df data_binary.txt -type c -n 15 -save test_bin -y_name yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ../test_set.py -df data_multiclass.txt -type c -n 15 -save test_mc -y_name yield"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the code above, you've generated three new files called test_reg, test_bin, and test_mc that should be in your working directory. These files contain the list of lines that will be held out of training and used to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regression models\n",
    "\n",
    "The machine learning algorithms in the ML_Pipeline are implement from [SciKit-Learn](https://scikit-learn.org/stable/), which has excellent resources to learn more about the ins and outs of these algorithms.\n",
    "\n",
    "Regression algorithms available in the pipeline are: Support Vector Regression with linear (SVM), polynomial (SVMpoly), and radial basis function (SVMrbf) kernels, Random Forest (RF), Gradient Tree Boosting (GB), Logistic Regression (LogReg).\n",
    "\n",
    "Note, there are many functions available within the pipeline that are not described in this tutorial. Run python ML_regression.py without any arguments to see more details!\n",
    "\n",
    "We'll start by using RF to predict maize grain yield using the test_reg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built using 388 instances\n",
      "Removing test instances to apply model on later...\n",
      "Snapshot of data being used:\n",
      "                 Y  GRMZM2G517408  GRMZM5G824831  GRMZM2G019971  \\\n",
      "04033v       0.945       4.000622       2.420715       0.379902   \n",
      "33-16        2.715       3.617671       2.177523       0.414420   \n",
      "38-11        2.210       3.474531       2.059158       0.220565   \n",
      "4554_inbred  0.695       4.154001       2.327104       1.649560   \n",
      "4578_inbred  1.855       3.876912       2.161319       0.794462   \n",
      "\n",
      "             GRMZM2G134393  GRMZM2G149617  GRMZM2G024624  GRMZM2G174574  \\\n",
      "04033v            1.673321       2.178089       0.218431       2.921370   \n",
      "33-16             2.087288       2.328111       0.685711       2.672112   \n",
      "38-11             1.777336       1.911081       0.000000       1.923086   \n",
      "4554_inbred       2.578617       1.925957       0.542716       1.340303   \n",
      "4578_inbred       2.566272       2.169369       0.047206       1.935339   \n",
      "\n",
      "             GRMZM2G412601  GRMZM2G371033      ...        GRMZM2G429714  \\\n",
      "04033v            3.821798       1.006910      ...             2.937997   \n",
      "33-16             3.102621       0.197594      ...             2.492875   \n",
      "38-11             2.735017       0.734812      ...             2.478754   \n",
      "4554_inbred       4.000860       0.229839      ...             2.845380   \n",
      "4578_inbred       3.645419       1.425558      ...             2.592160   \n",
      "\n",
      "             GRMZM2G125531  GRMZM2G154641  GRMZM2G158496  GRMZM2G082924  \\\n",
      "04033v            3.136064       2.279211       2.254448       3.214153   \n",
      "33-16             3.525225       2.028105       2.294453       3.025247   \n",
      "38-11             3.276937       2.559241       1.188042       2.581867   \n",
      "4554_inbred       3.221931       2.583537       1.771426       3.516925   \n",
      "4578_inbred       3.202978       2.768399       2.328836       3.945413   \n",
      "\n",
      "             GRMZM2G003368  GRMZM2G055917  GRMZM2G084406  GRMZM2G174136  \\\n",
      "04033v            2.003531       2.023021       2.965624       2.793567   \n",
      "33-16             1.280898       1.610659       3.019219       3.569451   \n",
      "38-11             1.869066       2.033939       2.822004       2.764172   \n",
      "4554_inbred       2.002754       2.323461       3.032517       3.541860   \n",
      "4578_inbred       1.640109       2.272249       3.189859       2.984115   \n",
      "\n",
      "             GRMZM2G346839  \n",
      "04033v            0.106836  \n",
      "33-16             0.000000  \n",
      "38-11             0.534746  \n",
      "4554_inbred       0.109644  \n",
      "4578_inbred       0.000000  \n",
      "\n",
      "[5 rows x 201 columns]\n",
      "\n",
      "\n",
      "===>  Grid search started  <===\n",
      "Round 1 of 2\n",
      "Round 2 of 2\n",
      "                        mean_test_score\n",
      "max_depth max_features                 \n",
      "10.0      0.1                 -0.422212\n",
      "          0.5                 -0.430879\n",
      "5.0       0.5                 -0.432182\n",
      "          0.1                 -0.436378\n",
      "          sqrt                -0.437773\n",
      "Parameter sweep time: 17.878568 seconds\n",
      "Parameters selected: max_depth=10.0, max_features=0.1\n",
      "Grid search complete. Time: 17.880806 seconds\n",
      "\n",
      "\n",
      "===>  ML Pipeline started  <===\n",
      "Running 1 of 2\n",
      "Running 2 of 2\n",
      "ML Pipeline time: 31.556998 seconds\n",
      "\n",
      "\n",
      "===>  ML Results  <===\n",
      "Metric\tMean\tstd\tSE\n",
      "MSE\t0.38589367091222454\t0.0010899007747032785\t0.0007706762286131597\n",
      "EVS\t0.34865573273935513\t0.001741058945066487\t0.0012311145865020097\n",
      "R2\t0.3475932496248866\t0.0018426283617831718\t0.0013029350098235396\n",
      "PCC\t0.6652830800149014\t0.0029940380915965403\t0.002117104637698743\n",
      "\n",
      "\n",
      "\n",
      "Test Set Scores:\n",
      "Metric\tMean\tstd\tSE\n",
      "\n",
      "MSE\t0.4945123654940019\t0.006402365401137727\t0.004527155990778617\n",
      "EVS\t0.2981640914996559\t0.009590392090714384\t0.006781431281581971\n",
      "R2\t0.2973144873409009\t0.009097546852312066\t0.006432937071432192\n",
      "PCC\t0.6079842001679554\t0.010680134373550088\t0.007551995439520806\n",
      "\n",
      "\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "%run ../ML_regression.py -df data_regression.txt -test test_reg -y_name yield \\\n",
    "-alg RF -gs true -gs_reps 2 -n 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results Breakdown**\n",
    "\n",
    "First, note that you see two sets of results, first results from the validation set followed by results from the test. If this is your final model, you can report the results from the test set, however, if you are going to compare this model to, say a model using a different algorithm, and then select which algorithm to use for your study, you want to use the validation set results. Basically, you want to avoid making any decisions about the modeling process using the test set results because it may lead to overfitting.\n",
    "\n",
    "For regression models, four performance metrics are reported ([MSE](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error), [EVS](https://scikit-learn.org/stable/modules/model_evaluation.html#explained-variance-score), [r2](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score), and [PCC](https://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html) along with the standard deviation (std) and standard error (se) over the replicates (n). In the case of regression models, each replicate is different because different [cross validation folds](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) are assigned to each replicate.\n",
    "\n",
    "One parameter that can be adjusted is how many cross validation folds you want to include (-cv). The default and a commonly used fold number is -cv 10, however, if you have a small dataset, using fewer folds (-cv 5) may perform better. In the extreme case, if you have very few instances to train on, you can set -cv equal to the number of instances in your dataset, allowing you to perform leave one out [LOO](https://www.cs.cmu.edu/~schneide/tut5/node42.html) cross validation.\n",
    "\n",
    "**Output files**\n",
    "\n",
    "You will also note that the pipeline generated a number of output files from your run. You can specify a prefix for these files using -save. Here is a breakdown of what you'll find in those files:\n",
    "\n",
    "- \"_results\": will give you a summary of the results from the run, similar to what you see when you run the pipeline on the command line.\n",
    "- \"_scores\": For each instance you see the original value to predict (Y), the mean and stdev prediction across all replicates, and the predicted Y for each replicate\n",
    "- \"_imp\": the importance of each feature in your model. For RF and GTB this score represents the [Gini Index](https://medium.com/the-artificial-impostor/feature-importance-measures-for-tree-models-part-i-47f187c1a2c3), while for LogReg and SVM it is the [coefficient](https://medium.com/@aneesha/visualising-top-features-in-linear-svm-with-scikit-learn-and-matplotlib-3454ab18a14d). SVM with non-linear kernels (i.e. poly, rbf) does not report importance scores.\n",
    "- \"_GridSearch\": the average performance metric across the whole possible parameter space tested via the grid search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Binary classification models\n",
    "\n",
    "All of the algorithms available for regression are also available for classification. The pipeline uses 1 and 0 as the default positive and negative classes, respectively. However, you can specify your own pos/neg classes using -pos POS_string -neg NEG_string. \n",
    "\n",
    "\n",
    "Lets try using SVM with a linear kernel to predict if a line is in the top 25% (pos) or bottom 75% (neg) for yield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing test instances to apply model on later...\n",
      "Snapshot of data being used:\n",
      "             Class  GRMZM2G517408  GRMZM5G824831  GRMZM2G019971  GRMZM2G134393\n",
      "33-16            1       0.584857       0.850034       0.201713       0.515018\n",
      "38-11            0       0.509846       0.803828       0.107357       0.361492\n",
      "4554_inbred      0       0.865917       0.908425       0.802900       0.758384\n",
      "80-2             0       0.684600       0.914129       0.788498       0.626799\n",
      "a                1       0.744183       0.830093       0.560451       0.588417\n",
      "CLASSES: [0 1]\n",
      "POS: 1 <class 'int'>\n",
      "NEG: 0 <class 'int'>\n",
      "Balanced dataset will include 81 instances of each class\n",
      "\n",
      "\n",
      "===>  Grid search started  <===\n",
      "Round 1 of 2\n",
      "Round 2 of 2\n",
      "Parameter sweep time: 3.759559 seconds\n",
      "Parameters selected: Kernel=Linear, C=0.01\n",
      "Grid search complete. Time: 3.760623 seconds\n",
      "\n",
      "\n",
      "===>  ML Pipeline started  <===\n",
      "  Round 1 of 2\n",
      "  Round 2 of 2\n",
      "ML Pipeline time: 0.943225 seconds\n",
      "\n",
      "\n",
      "===>  ML Results  <===\n",
      "\n",
      "Validation Set Scores\n",
      "Accuracy: 0.712963 (+/- stdev 0.021605)\n",
      "F1: 0.756251 (+/- stdev 0.008776)\n",
      "AUC-ROC: 0.796296 (+/- stdev 0.034979)\n",
      "AUC-PRC: 0.751981 (+/- stdev 0.050166)\n",
      "\n",
      "\n",
      "Test Set Scores:\n",
      "Precision: 0.632479\n",
      "Accuracy: 0.691358\n",
      "F1: 0.747475\n",
      "AUC-ROC: 0.877778 (+/- stdev 0.028889)\n",
      "AUC-PRC: 0.887896 (+/- stdev 0.027596)\n",
      "finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/GitHub/ML-Pipeline/ML_classification.py:368: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  AucRoc_array.append(r['AucRoc'])\n"
     ]
    }
   ],
   "source": [
    "%run ../ML_classification -df data_binary.txt -test test_bin -y_name yield \\\n",
    "-alg SVM -gs true -gs_reps 2 -n 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results Breakdown**\n",
    "\n",
    "First, note that before the grid search started running, the model told you what your positive and negative class strings were and how many instances would be in each class for each replicate. This is an important feature in the ML-Pipeline. Training a ML classifier with unbalanced data, or data with different numbers of each instance, can cause your model to be biased toward predicting the more numerous class. For example, if you train a model using 100 positive examples and 100,000 negative examples, your model would do well to just call instance negative! Therefore, in this pipeline, the larger classes are randomly downsampled to generate balanced datasets. To ensure we still utilize as much data as possible, this downsampling is done independelty for each replicate (-n). \n",
    "\n",
    "A number of performance metrics are included for binary classification models, including [AUC-ROC](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html), [F-measure](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html), [AUC-PRC](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html), [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html), and [precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score).\n",
    "\n",
    "**Output files**\n",
    "\n",
    "The classficiation pipeline generates similar output as the regression pipeline, although there are a few notable differences. \n",
    "\n",
    "- \"_scores\": Here, the predicted probability (pp) scores are reported for each replicate. The pp score represents how confident the model was in its classification, where a pp=1 means it is certain the instance is positive and pp=0 means it is certain the instance is negative. For each replicate, an instance is classified as pos if pp > threshold, which is defined as value between 0.001-0.999 that maximises the F-measure. While the performance metrics generated by the pipeline are calcuated for each replicate independently, we want to be able to make a final statement about which instances were called as positive and which were called as negative. You'll find those results in this file. To make this final call we calculated the mean threshold and the mean pp for each instance and called the instance pos if the mean pp > mean threshold. \n",
    "- \"_results\": Here you will see an overview of the results similar to what is printed in the command line. However, for classification problems you will see two additional sections: the Mean Balanced Confusion Matrix (CM and the Final Full CM. The mean balanced CM was generated by taking the average number of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) across all replicate (which have been downsampled randomly to be balanced). The Final Full CM represents the final TP, TN, FP, and FN results from the final pos/neg classifications (descirbed above in _scores) for all instances in your input dataset. \n",
    "- \"_BalancedID\": Each row lists the instances that were included in each replicate (-n) after downsampling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-class classification models\n",
    "\n",
    "All of the algorithms available for regression and binary classification are also available for multiclass classification. There are no default classes for multiclass models, so you will have to specity what classes are including using (-cl_train)\n",
    "\n",
    "\n",
    "Lets try using SVM with a linear kernel to predict if a line is in the top 25% (2) or middle 50% (1) or bottom 25% (0) for yield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing test instances to apply model on later...\n",
      "Snapshot of data being used:\n",
      "             Class  GRMZM2G517408  GRMZM5G824831  GRMZM2G019971  GRMZM2G134393\n",
      "04033v           0       0.785540       0.944968       0.184912       0.309971\n",
      "33-16            2       0.584857       0.850034       0.201713       0.515018\n",
      "38-11            1       0.509846       0.803828       0.107357       0.361492\n",
      "4554_inbred      0       0.865917       0.908425       0.802900       0.758384\n",
      "4578_inbred      1       0.720710       0.843708       0.386693       0.752269\n",
      "CLASSES: ['0' '1' '2']\n",
      "POS: 0 <class 'str'>\n",
      "NEG: multiclass_no_NEG <class 'str'>\n",
      "Balanced dataset will include 96 instances of each class\n",
      "\n",
      "\n",
      "===>  Grid search started  <===\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "data type \"\" not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/GitHub/ML-Pipeline/ML_classification.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/GitHub/ML-Pipeline/ML_classification.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n===>  Grid search started  <===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                 \u001b[0mparams2use\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbalanced_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mML\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgs_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgs_reps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgs_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNEG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgs_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0;31m# Print results from grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/ML-Pipeline/ML_functions.py\u001b[0m in \u001b[0;36mGridSearch\u001b[0;34m(df, SAVE, ALG, classes, min_size, gs_score, n, cv_num, n_jobs, GS_REPS, GS_TYPE, POS, NEG, gs_full)\u001b[0m\n\u001b[1;32m     86\u001b[0m                         \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mcl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                                 \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                                 \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid type comparison\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_datetimelike_v_numeric\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0mis_datetimelike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneeds_i8_conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return ((is_datetimelike(a) and is_numeric(b)) or\n\u001b[0;32m-> 1349\u001b[0;31m             (is_datetimelike(b) and is_numeric(a)))\n\u001b[0m\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mneeds_i8_conversion\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr_or_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m     return (is_datetime_or_timedelta_dtype(arr_or_dtype) or\n\u001b[0m\u001b[1;32m   1442\u001b[0m             \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             is_period_dtype(arr_or_dtype))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_datetime_or_timedelta_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr_or_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m     \u001b[0mtipo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_dtype_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtipo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36m_get_dtype_type\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1870\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_interval_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1871\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mIntervalDtypeType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1872\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_dtype_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1873\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr_or_dtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: data type \"\" not understood"
     ]
    }
   ],
   "source": [
    "%run ../ML_classification.py -df data_multiclass.txt -test test_mc -y_name yield \\\n",
    "-cl_train 0,1,2 -alg SVM -gs true -gs_reps 2 -n 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
