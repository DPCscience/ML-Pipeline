{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Workshop\n",
    "\n",
    "Here we will walk through an example of a machine learning workflow following five steps:\n",
    "\n",
    "<img src=\"../_img/ml_workflow.png\" alt=\"ML Workflow\" width=\"800\"/>\n",
    "\n",
    "For more detailed information on the Shiu Lab's ML pipeline, including explanations of all output files,\n",
    "check out the [README](https://github.com/ShiuLab/ML-Pipeline).\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0. Set up Jupyter notebook & software\n",
    "\n",
    "Check out this [**guide**](../Tutorial/README.md) to learn how to set up Jupyter notebook and the software needed to run the Shiu Lab's ML pipeline.\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Step 1](../_img/step1.png \"ML Workflow step 1\")\n",
    "\n",
    "**What do we want to predict?** \n",
    "\n",
    "If a gene is annotated as being involved in specialized or general metabolism. \n",
    "\n",
    "**What are the labeled instances?**\n",
    "\n",
    "Tomato genes annotated as being involved in specialized or general metabolism by TomatoCyc.\n",
    "\n",
    "**What are the predictive features?** \n",
    "- duplication information (e.g. number of paralogs, gene family size)\n",
    "- sequence conservation (e.g. nonsynonymous/synonymouse substitution rates between homologs)\n",
    "- gene expression (e.g. breadth, stress specific, co-expression)\n",
    "- protein domain conent (e.g. p450, Aldedh)\n",
    "- epigenetic modification (e.g. H3K23ac histone marks)\n",
    "- network properties (# protein-protein interactions, network connectivity).\n",
    "\n",
    "**What data do we have?**\n",
    "- 532 tomato genes with specialized metabolism annotation by TomatoCyc\n",
    "- 2,318 tomato genes with general metabolism annotation by TomatoCyc\n",
    "- 4,197 features (we are only using a subset of **564** for this workshop)\n",
    "\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Step 2](../_img/step2.png \"ML Workflow step 2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data (rows, cols):\n",
      "(2872, 565)\n",
      "\n",
      "Snapshot of data:\n",
      "                Class  Crubella_183_v1.0.csv  FamilySize FamilySize_cat  \\\n",
      "YP_008563134      gen                    0.0    0.010582         medium   \n",
      "XP_010327628      gen                    0.0    0.000000          small   \n",
      "XP_010327620  special                    0.0    0.052910         medium   \n",
      "XP_010327578      gen                    0.0         NaN            NaN   \n",
      "XP_010327494      gen                    1.0    0.021164         medium   \n",
      "YP_008563119  special                    0.0    0.000000          small   \n",
      "\n",
      "              Transferase  \n",
      "YP_008563134          0.0  \n",
      "XP_010327628          NaN  \n",
      "XP_010327620          0.0  \n",
      "XP_010327578          0.0  \n",
      "XP_010327494          0.0  \n",
      "YP_008563119          0.0  \n",
      "\n",
      "List of class labels\n",
      "gen        2318\n",
      "special     532\n",
      "unknown      22\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## A. Lets look at the data (note, you can do this in excel or R!)\n",
    "import pandas as pd\n",
    "\n",
    "d = pd.read_table('data.txt', sep='\\t', index_col = 0)\n",
    "\n",
    "print('Shape of data (rows, cols):')\n",
    "print(d.shape)\n",
    "\n",
    "print('\\nSnapshot of data:')\n",
    "print(d.iloc[:6,:5])  # prints first 6 rows and 5 columns\n",
    "\n",
    "print('\\nList of class labels')\n",
    "print(d['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Things to notice:**\n",
    "- Our data has NAs. ML algorithms cannot handel NAs. We either needs to drop or impute NA values!\n",
    "- We have binary, continuous, and categorical features in this dataset. A perk of ML models is that they can integrate multiple datatypes in a single model. \n",
    "- However, before being used as input, a categorical feature needs to be converted into set binary features using an approach called [one-hot-encoding](https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding). \n",
    "\n",
    "*Before One-Hot Encoding:*\n",
    "\n",
    "| ID   | Class    | Weather   |\n",
    "|---    |---    |---    |\n",
    "| instance_A    |  1     | sunny     |\n",
    "| instance_B    |  0    |  overcast     |\n",
    "| instance_C   |  0     |  rain    | \n",
    "| instance_D   | 1     |  sunny    |\n",
    "\n",
    "*After One-Hot Encoding:*\n",
    "\n",
    "| ID   | Class    | Weather_sunny   | Weather_overcast   | Weather_rain   |\n",
    "|---    |---    |---    |---    |---    |\n",
    "| instance_A    |  1     | 1     | 0     | 0     |\n",
    "| instance_B    |  0    |  0     |  1     |  0     |\n",
    "| instance_C   |  0     |  0    |  0    |  1    | \n",
    "| instance_D   | 1     |  1    | 0    | 0    |\n",
    "\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated data cleaning: ML_preprocess.py\n",
    "\n",
    "Input\n",
    "```\n",
    "-df: your data table\n",
    "-na_method: how you want to impute NAs (options: drop, mean, median, mode)\n",
    "-h: show more options\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot of input data...\n",
      "                Class  Crubella_183_v1.0.csv  FamilySize FamilySize_cat  \\\n",
      "YP_008563134      gen                    0.0    0.010582         medium   \n",
      "XP_010327628      gen                    0.0    0.000000          small   \n",
      "XP_010327620  special                    0.0    0.052910         medium   \n",
      "XP_010327578      gen                    0.0         NaN            NaN   \n",
      "XP_010327494      gen                    1.0    0.021164         medium   \n",
      "\n",
      "              Transferase  \n",
      "YP_008563134          0.0  \n",
      "XP_010327628          NaN  \n",
      "XP_010327620          0.0  \n",
      "XP_010327578          0.0  \n",
      "XP_010327494          0.0  \n",
      "\n",
      "\n",
      "### Dropping/imputing NAs... ###\n",
      "\n",
      "Number of columns with NAs: 41\n",
      "Features dropped because missing > 50.00% of data: ['SQS_PSY']\n",
      "Number of columns to impute: 40\n",
      "\n",
      "\n",
      "### One Hot Encoding... ###\n",
      "\n",
      "Features to one-hot-encode: ['FamilySize_cat']\n",
      "Dataframe shape (rows, cols) before and after one-hot-encoding:\n",
      "Before: (2872, 563)\n",
      "After: (2872, 565)\n",
      "\n",
      "Number of duplicate row names to delete: 0\n",
      "\n",
      "Snapshot of imputed data...\n",
      "                Class  Crubella_183_v1.0.csv  FamilySize  Transferase  \\\n",
      "YP_008563134      gen                    0.0    0.010582          0.0   \n",
      "XP_010327628      gen                    0.0    0.000000          0.0   \n",
      "XP_010327620  special                    0.0    0.052910          0.0   \n",
      "XP_010327578      gen                    0.0    0.015873          0.0   \n",
      "XP_010327494      gen                    1.0    0.021164          0.0   \n",
      "\n",
      "              Exo_endo_phos  \n",
      "YP_008563134            0.0  \n",
      "XP_010327628            0.0  \n",
      "XP_010327620            0.0  \n",
      "XP_010327578            0.0  \n",
      "XP_010327494            0.0  \n",
      "\n",
      "Output file saved as: data_mod.txt\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# B. Drop/Impute NAs and one-hot-encode categorical features\n",
    "\n",
    "%run ../ML_preprocess.py -df data.txt -na_method median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Set aside instances for testing \n",
    "\n",
    "We want to set aside a subset of our data to use to test how well our model performed. Note that this is done before feature engineering, parameter selection, or model training. This will ensure our performance metric is entirely independent from our modeling!\n",
    "\n",
    "\n",
    "### Automated selection of test set: test_set.py\n",
    "\n",
    "Input\n",
    "```\n",
    "-df: your data table\n",
    "-use: what class labels to include in the test set (we don't want to include unknowns!)\n",
    "-type: (c) classification or (r) regression\n",
    "-p: What percent of instances from each class to select for test (0.1 = 10%)\n",
    "-save: save name for test set\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holding out 10.0 percent\n",
      "Pulling test set from classes: ['gen', 'special']\n",
      "285 instances in test set\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "# C. Define test set\n",
    "\n",
    "%run ../test_set.py -df data_mod.txt -use gen,special -type c -p 0.1 -save test_genes2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "\n",
    "![Step 3](../_img/step3.png \"ML Workflow step 3\")\n",
    "\n",
    "While one major advantage of ML approaches is that they are robust when the number of features is very large, there are cases where removing unuseful features or selecting only the best features may help you better answer your question. One common issue we see with using feature selection for machine learning is using the whole dataset to select the best features, which results in overfitting! **Be sure you specify your test set so that this data is not used for feature selection!**\n",
    "\n",
    "\n",
    "### Automated feature selection: Feature_Selection.py\n",
    "\n",
    "Input\n",
    "```\n",
    "-df: your data table\n",
    "-test: what instances to hold out (i.e. test instances!)\n",
    "-cl_train: labels to include in training the feature selection algorithm\n",
    "-type: (c) classification or (r) regression\n",
    "-alg: what feature selection algorithm to use (e.g. lasso, elastic net, random forest)\n",
    "-p: Parameter specific to different algorithms (use -h for more information)\n",
    "-save: save name for list of selected features\n",
    "```\n",
    "\n",
    "\n",
    "Here we will use one of the most common feature selection algorithms: LASSO. LASSO requires the user to select the level of sparcity (-p) they want to induce during feature selection, where a larger value will result in more features being selected and a smaller value resulting in fewer features being selected. You can play around with this value to see what it does for your data.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing testldout instances...\n",
      "Dropping instances that are not in ['special', 'gen'], changed dimensions from (2587, 566) to (2565, 566) (instance, features).\n",
      "\n",
      "Snapshot of data:\n",
      "              Class  Crubella_183_v1.0.csv  FamilySize  Transferase  \\\n",
      "XP_010327628      0                    0.0    0.000000          0.0   \n",
      "XP_010327620      1                    0.0    0.052910          0.0   \n",
      "XP_010327578      0                    0.0    0.015873          0.0   \n",
      "XP_010327494      0                    1.0    0.021164          0.0   \n",
      "YP_008563119      1                    0.0    0.000000          0.0   \n",
      "YP_008563115      0                    0.0    0.010582          0.0   \n",
      "\n",
      "              Exo_endo_phos  \n",
      "XP_010327628            0.0  \n",
      "XP_010327620            0.0  \n",
      "XP_010327578            0.0  \n",
      "XP_010327494            0.0  \n",
      "YP_008563119            0.0  \n",
      "YP_008563115            0.0  \n",
      "=====* Running L1/LASSO based feature selection *=====\n",
      "Features selected using LASSO: ['Transferase' 'Exo_endo_phos' 'Pkinase_Tyr' 'Ins134_P3_kin'\n",
      " 'GHMP_kinases_N' 'Lycopene_cycl' 'Peptidase_S10' 'Chal_sti_synt_N'\n",
      " 'HMG.CoA_red' 'Methyltransf_7' 'Pyridoxal_deC' 'Chalcone'\n",
      " 'Sulfotransfer_1' 'Glyco_hydro_1' 'NeighborSMCount' 'p450'\n",
      " 'Terpene_synth_C' 'Lipoxygenase' 'UDPGT' 'Abhydrolase_3' 'Pabies_maxKaKs'\n",
      " 'PLAT' 'Alyrata_medKaKs' 'Methyltransf_3' 'ADH_N' 'Tcacao_maxKaKs'\n",
      " 'DIOX_N' 'NAD_binding_10' 'Ccanephora_maxKaKs' 'Methyltransf_2'\n",
      " 'Lipocalin' 'Lipocalin_2' 'X2OG.FeII_Oxy' 'NmrA' 'Dimerisation'\n",
      " 'SQHop_cyclase_N' 'Prenyltrans' 'SQHop_cyclase_C' 'NAD_binding_8'\n",
      " 'Atrichopoda_medKaKs' 'Epimerase' 'Atrichopoda_maxKaKs' 'KR'\n",
      " 'develop_expr_breadth' 'Terpene_synth' 'stress_SM_corr_max'\n",
      " 'hormone_expr_breadth_uponly' 'abiotic.shoot_expr_breadth_downonly'\n",
      " 'abiotic.shoot_expr_breadth_uponly' 'tandemDupGenes'\n",
      " 'Nicotiana_tabacum.TN90_AYMY.SS.csv' 'adh_short_C2'\n",
      " 'biotic_expr_breadth_downonly' 'Acoerulea_322_v3.1.csv'\n",
      " 'Coffea_canephora.csv' 'Tcacao_233_v1.1.csv' 'node_4' 'node_0'\n",
      " 'Nicotiana_tomen.csv' 'node_7' 'node_1' 'Ppatens_maxKaKs' 'ECH_1'\n",
      " 'Pectinesterase' 'Aminotran_1_2' 'NeighborGMCount' 'RmlD_sub_bind'\n",
      " 'Polysacc_synt_2' 'Exostosin' 'Glyco_hydro_28' 'Lipase_3' 'Glutaredoxin'\n",
      " 'FamilySize_cat_large' 'FamilySize_cat_small']\n",
      "\n",
      "Number of features selected using LASSO (sparcity parameter = 0.1): 74\n",
      "Run time (sec):0.4\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%run ../Feature_Selection.py -df data_mod.txt -test test_genes.txt -cl_train special,gen -type c -alg lasso -p 0.1 -save top_feat_lasso.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "![Step 4](../_img/step4.png \"ML Workflow step 4\")\n",
    "\n",
    "Next we want to determine which ML algorithm (i.e. Support Vector Machine (SVM), Random Forest (RF)) we should use and what parameters needed by those algorithms work best. Importantly, at this stage we **only assess our model performance on the validation data** in order to assure we aren't just selecting the algorithm that works best on our held out testing data. The pipeline will automatically withhold the testing data from the parameter selection (i.e. grid search) step. \n",
    "\n",
    "The machine learning algorithms in the ML_Pipeline are implement from [SciKit-Learn](https://scikit-learn.org/stable/), which has excellent resources to learn more about the ins and outs of these algorithms.\n",
    "\n",
    "Algorithms available in the pipeline are: Support Vector Machine (linear: SVM, polynomial: SVMpoly, radial basis function: SVMrbf), Random Forest (RF), Gradient Tree Boosting (GB), and Logistic Regression (LogReg).\n",
    "\n",
    "\n",
    "### Parameter Selection\n",
    "\n",
    "There are two general strategies for parameter selection: the grid search (default option: left) and the random search (use \"-gs_type random\": right):\n",
    "![Grid search](../_img/grid_rand_search.png \"Grid Search\")\n",
    "*Image: Bergstra & Bengio 2012; used under CC-BY license*\n",
    "\n",
    "\n",
    "### Training and Validation\n",
    "\n",
    "Training and validation is done using a [cross-validation (CV)](https://towardsdatascience.com/cross-validation-70289113a072) scheme. CV is useful because it makes good use of our data (i.e. uses all non-test data for training at some point) but also makes sure we are selecting the best parameters/algorithms on models that aren't overfit to the training data. Here is a visual to demonstrate how CV works (with 10-cv folds in this example):\n",
    "\n",
    "![Cross Validation](../_img/cross_validation.png \"Cross validation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated parameter selection, ML training, validation, & testing:  ML_classification.py/ML_regression.py\n",
    "\n",
    "Input\n",
    "```\n",
    "-df: your data table\n",
    "-test: what instances to hold out (i.e. test instances)\n",
    "-cl_train: labels to include in training the feature selection algorithm\n",
    "-alg: what ML algorithm to use (e.g. SVM, RF, LogReg)\n",
    "-cv: Number of cross-validation folds (default = 10, use fewer if data set is small)\n",
    "-save: save name for list of selected features\n",
    "```\n",
    "\n",
    "**There are many functions available within the pipeline that are not described in this workshop. For more options run:**\n",
    "\n",
    "```\n",
    "python ML_classification.py -h\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing test instances to apply model on later...\n",
      "Snapshot of data being used:\n",
      "                Class  Crubella_183_v1.0.csv  FamilySize  Transferase  \\\n",
      "XP_010327628      gen                    0.0    0.000000          0.0   \n",
      "XP_010327620  special                    0.0    0.083333          0.0   \n",
      "XP_010327578      gen                    0.0    0.025000          0.0   \n",
      "XP_010327494      gen                    1.0    0.033333          0.0   \n",
      "YP_008563119  special                    0.0    0.000000          0.0   \n",
      "\n",
      "              Exo_endo_phos  \n",
      "XP_010327628            0.0  \n",
      "XP_010327620            0.0  \n",
      "XP_010327578            0.0  \n",
      "XP_010327494            0.0  \n",
      "YP_008563119            0.0  \n",
      "\n",
      "\n",
      "CLASSES: ['gen' 'special']\n",
      "POS: special type:  <class 'str'>\n",
      "NEG: gen type:  <class 'str'>\n",
      "\n",
      "Balanced dataset will include 478 instances of each class\n",
      "\n",
      "\n",
      "===>  Grid search started  <===\n",
      "Round 1 of 10\n",
      "Round 2 of 10\n",
      "Round 3 of 10\n",
      "Round 4 of 10\n",
      "Round 5 of 10\n",
      "Round 6 of 10\n",
      "Round 7 of 10\n",
      "Round 8 of 10\n",
      "Round 9 of 10\n",
      "Round 10 of 10\n",
      "Parameter sweep time: 18.502701 seconds\n",
      "Parameters selected: Kernel=Linear, C=0.5\n",
      "Grid search complete. Time: 18.527073 seconds\n",
      "\n",
      "\n",
      "===>  ML Pipeline started  <===\n",
      "  Round 1 of 10\n",
      "  Round 2 of 10\n",
      "  Round 3 of 10\n",
      "  Round 4 of 10\n",
      "  Round 5 of 10\n",
      "  Round 6 of 10\n",
      "  Round 7 of 10\n",
      "  Round 8 of 10\n",
      "  Round 9 of 10\n",
      "  Round 10 of 10\n",
      "ML Pipeline time: 12.444290 seconds\n",
      "\n",
      "\n",
      "===>  ML Results  <===\n",
      "\n",
      "Validation Set Scores\n",
      "Accuracy: 0.851987 (+/- stdev 0.006927)\n",
      "F1: 0.856199 (+/- stdev 0.006305)\n",
      "AUC-ROC: 0.911239 (+/- stdev 0.006665)\n",
      "AUC-PRC: 0.909955 (+/- stdev 0.010014)\n",
      "\n",
      "\n",
      "Test Set Scores:\n",
      "Precision: 0.833663\n",
      "Accuracy: 0.852510\n",
      "F1: 0.856562\n",
      "AUC-ROC: 0.924317 (+/- stdev 0.006282)\n",
      "AUC-PRC: 0.811295 (+/- stdev 0.031542)\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "%run ../ML_classification.py -df data_mod.txt -test test_genes.txt -cl_train special,gen -alg SVM -cv 5 -gs true -gs_reps 10 -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results Breakdown**\n",
    "\n",
    "The output here includes the results on both the validation data (selected randomly interally during the modeling process) and on the held out testing data. Since now we are just selecting the best algorithm/parameters, only look at the validation scores. \n",
    "\n",
    "SS doing AUC-ROC. I'll talk about F1 and AUC-ROC, mention many other performance metrics available. \n",
    "\n",
    "** Comparing algorithms **\n",
    "\n",
    "Running the same script (only changing **-alg XXX**), performance on the validation data using other algorithms:\n",
    "\n",
    "| Alg  \t| F1  \t| AUC-ROC  \t|\n",
    "|---\t|---\t|---\t|\n",
    "| RF  \t| 0.757  \t| 0.824  \t|\n",
    "| LogReg  \t| 0.862  \t| 0.921  \t|\n",
    "| SVMpoly  \t|   \t|   \t|\n",
    "| SVM  \t| 0.848  \t| 0.898  \t|\n",
    "\n",
    "\n",
    "** performed best on the validation data so we will select that algorithm! **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Step 5](../_img/step5.png \"ML Workflow step 5\")\n",
    "\n",
    "Now that we have our best performing algorithm, we will run the pipeline one more time, but with more replicates and we will use it to predict our unknown genes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../ML_classification.py -df data_mod.txt -test test_genes.txt -cl_train special,gen -apply unknown -plots T -alg SVM -cv 5 -gs true -gs_reps 10 -n 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check out our results**\n",
    "\n",
    "(For a detailed description of the content of the pipeline output see the [README](../README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if you do things differently\n",
    "\n",
    "Top few features\n",
    "Top 50 ish features\n",
    "\n",
    "Use smaller balenced data set\n",
    "\n",
    "### Advanced Topics\n",
    "- multiclass\n",
    "- transfer learning\n",
    "- venn diagrams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.D Visualizing Your Results\n",
    "\n",
    "There are a number of vizualization tools available in the ML-Pipeline. We will describe just some of them here!\n",
    "\n",
    "**Generate Plots while training and testing your models**\n",
    "\n",
    "1. One optional parameter for both the ML_classification.py and ML_regression.py pipelines is -plots T/F. The default is False, but if you want to generate some plots directly during your ML run, set -plots T. For classification you will get an [AUC-ROC plot](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5) and an [AUC-PRC plot](https://classeval.wordpress.com/introduction/introduction-to-the-precision-recall-plot/). \n",
    "\n",
    "2. In the ML_classification.py pipeline, another plotting option is to auto-generate a [confusion matrix heatmap](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62) (-cm), just set -cm T\n",
    "\n",
    "**Generate plots post-model building**\n",
    "1. **ML_plots.py** allows you to generate AUC-ROC and AUC-PRC plots from multiple runs, for example if you wanted to compare performance of different algorithms or using different sets of features. For example, we can compare the results from our classification model with all 200 features with the one generated using the top 15 features:\n",
    "\n",
    "```\n",
    "ML_plots.py [SAVE_NAME] [POS] [NEG] [M1_name] [PATH_M1_scores] [M2_name] [PATH_M2_scores]... [Mn_name] [PATH_Mn_scores]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../ML_plots.py binary_plots 1 0 all data_binary.txt_SVM_scores.txt top15 data_binary_SVM_top15_scores.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **compare_classifiers.py** takes in the results from different classification models and generates a list of which instances were correctly and incorrectly predicted by each model and generates a venn diagram showing the overlap.\n",
    "\n",
    "```\n",
    "ML_plots.py -scores PATH_M1_scores,PATH_M2_scores,...,PATH_Mn_scores -ids M1_name,M2_name,...,Mn_name -save [SAVE_NAME]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../compare_classifiers.py  -scores data_binary.txt_SVM_scores.txt,data_binary_SVM_top15_scores.txt -ids all,top15 -save binary_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results indicate that our models using all and the top 15 features both predicted 88 instances correctly as positive, but only 82 of those instances were the same for both models, meaning they each uniquely correctly classified 6 instances as positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced Topics:\n",
    "\n",
    "- One parameter that can be adjusted in the ML_classification.py or ML_regression.py script is how many cross validation folds you want to include (-cv). The default and a commonly used fold number is -cv 10, however, if you have a small dataset, using fewer folds (-cv 5) may perform better. In the extreme case, if you have very few instances to train on, you can set -cv equal to the number of instances in your dataset, allowing you to perform leave one out LOO cross validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
