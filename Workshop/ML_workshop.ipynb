{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Workshop\n",
    "\n",
    "Here we will walk through an example of a machine learning workflow following five steps:\n",
    "\n",
    "<img src=\"../_img/ml_workflow.png\" alt=\"ML Workflow\" width=\"800\"/>\n",
    "\n",
    "For more detailed information on the Shiu Lab's ML pipeline, including explanations of all output files,\n",
    "check out the [README](https://github.com/ShiuLab/ML-Pipeline).\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0. Set up Jupyter notebook & software\n",
    "\n",
    "Check out this [**guide**](../Tutorial/README.md) to learn how to set up Jupyter notebook and the software needed to run the Shiu Lab's ML pipeline.\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Step 1](../_img/step1.png \"ML Workflow step 1\")\n",
    "\n",
    "**What do we want to predict?** \n",
    "\n",
    "If a gene is annotated as being involved in specialized or general metabolism. \n",
    "\n",
    "**What are the labeled instances?**\n",
    "\n",
    "Tomato genes annotated as being involved in specialized or general metabolism by TomatoCyc.\n",
    "\n",
    "**What are the predictive features?** \n",
    "- duplication information (e.g. number of paralogs, gene family size)\n",
    "- sequence conservation (e.g. nonsynonymous/synonymouse substitution rates between homologs)\n",
    "- gene expression (e.g. breadth, stress specific, co-expression)\n",
    "- protein domain conent (e.g. p450, Aldedh)\n",
    "- epigenetic modification (e.g. H3K23ac histone marks)\n",
    "- network properties (# protein-protein interactions, network connectivity).\n",
    "\n",
    "**What data do we have?**\n",
    "- 532 tomato genes with specialized metabolism annotation by TomatoCyc\n",
    "- 2,318 tomato genes with general metabolism annotation by TomatoCyc\n",
    "- 4,197 features (we are only using a subset of **564** for this workshop)\n",
    "\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Step 2](../_img/step2.png \"ML Workflow step 2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data (rows, cols):\n",
      "(2872, 565)\n",
      "\n",
      "Snapshot of data:\n",
      "                Class  Crubella_183_v1.0.csv  FamilySize FamilySize_cat  \\\n",
      "YP_008563134      gen                    0.0    0.010582         medium   \n",
      "XP_010327628      gen                    0.0    0.000000          small   \n",
      "XP_010327620  special                    0.0    0.052910         medium   \n",
      "XP_010327578      gen                    0.0         NaN            NaN   \n",
      "XP_010327494      gen                    1.0    0.021164         medium   \n",
      "YP_008563119  special                    0.0    0.000000          small   \n",
      "\n",
      "              Transferase  \n",
      "YP_008563134          0.0  \n",
      "XP_010327628          NaN  \n",
      "XP_010327620          0.0  \n",
      "XP_010327578          0.0  \n",
      "XP_010327494          0.0  \n",
      "YP_008563119          0.0  \n",
      "\n",
      "List of class labels\n",
      "gen        2318\n",
      "special     532\n",
      "unknown      22\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## A. Lets look at the data (note, you can do this in excel or R!)\n",
    "import pandas as pd\n",
    "\n",
    "d = pd.read_table('data.txt', sep='\\t', index_col = 0)\n",
    "\n",
    "print('Shape of data (rows, cols):')\n",
    "print(d.shape)\n",
    "\n",
    "print('\\nSnapshot of data:')\n",
    "print(d.iloc[:6,:5])  # prints first 6 rows and 5 columns\n",
    "\n",
    "print('\\nList of class labels')\n",
    "print(d['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Things to notice:**\n",
    "- Our data has NAs. ML algorithms cannot handel NAs. We either needs to drop or impute NA values!\n",
    "- We have binary, continuous, and categorical features in this dataset. A perk of ML models is that they can integrate multiple datatypes in a single model. \n",
    "- However, before being used as input, a categorical feature needs to be converted into set binary features using an approach called [one-hot-encoding](https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding). \n",
    "\n",
    "*Before One-Hot Encoding:*\n",
    "\n",
    "| ID   | Class    | Weather   |\n",
    "|---    |---    |---    |\n",
    "| instance_A    |  1     | sunny     |\n",
    "| instance_B    |  0    |  overcast     |\n",
    "| instance_C   |  0     |  rain    | \n",
    "| instance_D   | 1     |  sunny    |\n",
    "\n",
    "*After One-Hot Encoding:*\n",
    "\n",
    "| ID   | Class    | Weather_sunny   | Weather_overcast   | Weather_rain   |\n",
    "|---    |---    |---    |---    |---    |\n",
    "| instance_A    |  1     | 1     | 0     | 0     |\n",
    "| instance_B    |  0    |  0     |  1     |  0     |\n",
    "| instance_C   |  0     |  0    |  0    |  1    | \n",
    "| instance_D   | 1     |  1    | 0    | 0    |\n",
    "\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated data cleaning: ML_preprocess.py\n",
    "\n",
    "Input\n",
    "```\n",
    "-df: your data table\n",
    "-na_method: how you want to impute NAs (options: drop, mean, median, mode)\n",
    "-h: show more options\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot of input data...\n",
      "                Class  Crubella_183_v1.0.csv  FamilySize FamilySize_cat  \\\n",
      "YP_008563134      gen                    0.0    0.010582         medium   \n",
      "XP_010327628      gen                    0.0    0.000000          small   \n",
      "XP_010327620  special                    0.0    0.052910         medium   \n",
      "XP_010327578      gen                    0.0         NaN            NaN   \n",
      "XP_010327494      gen                    1.0    0.021164         medium   \n",
      "\n",
      "              Transferase  \n",
      "YP_008563134          0.0  \n",
      "XP_010327628          NaN  \n",
      "XP_010327620          0.0  \n",
      "XP_010327578          0.0  \n",
      "XP_010327494          0.0  \n",
      "\n",
      "\n",
      "### Dropping/imputing NAs... ###\n",
      "\n",
      "Number of columns with NAs: 41\n",
      "Features dropped because missing > 50.00% of data: ['SQS_PSY']\n",
      "Number of columns to impute: 40\n",
      "\n",
      "\n",
      "### One Hot Encoding... ###\n",
      "\n",
      "Features to one-hot-encode: ['FamilySize_cat']\n",
      "Dataframe shape (rows, cols) before and after one-hot-encoding:\n",
      "Before: (2872, 563)\n",
      "After: (2872, 565)\n",
      "\n",
      "Number of duplicate row names to delete: 0\n",
      "\n",
      "Snapshot of imputed data...\n",
      "                Class  Crubella_183_v1.0.csv  FamilySize  Transferase  \\\n",
      "YP_008563134      gen                    0.0    0.010582          0.0   \n",
      "XP_010327628      gen                    0.0    0.000000          0.0   \n",
      "XP_010327620  special                    0.0    0.052910          0.0   \n",
      "XP_010327578      gen                    0.0    0.015873          0.0   \n",
      "XP_010327494      gen                    1.0    0.021164          0.0   \n",
      "\n",
      "              Exo_endo_phos  \n",
      "YP_008563134            0.0  \n",
      "XP_010327628            0.0  \n",
      "XP_010327620            0.0  \n",
      "XP_010327578            0.0  \n",
      "XP_010327494            0.0  \n",
      "\n",
      "Output file saved as: data_mod.txt\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# B. Drop/Impute NAs and one-hot-encode categorical features\n",
    "\n",
    "%run ../ML_preprocess.py -df data.txt -na_method median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Set aside instances for testing \n",
    "\n",
    "We want to set aside a subset of our data to use to test how well our model performed. Note that this is done before feature engineering, parameter selection, or model training. This will ensure our performance metric is entirely independent from our modeling!\n",
    "\n",
    "\n",
    "### Automated selection of test set: test_set.py\n",
    "\n",
    "Input\n",
    "```\n",
    "-df: your data table\n",
    "-use: what class labels to include in the test set (we don't want to include unknowns!)\n",
    "-type: (c) classification or (r) regression\n",
    "-p: What percent of instances from each class to select for test (0.1 = 10%)\n",
    "-save: save name for test set\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holding out 10.0 percent\n",
      "Pulling test set from classes: ['gen', 'special']\n",
      "285 instances in test set\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "# C. Define test set\n",
    "\n",
    "%run ../test_set.py -df data_mod.txt  \\\n",
    "                    -use gen,special  \\\n",
    "                    -type c  \\\n",
    "                    -p 0.1  \\\n",
    "                    -save test_genes.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "\n",
    "![Step 3](../_img/step3.png \"ML Workflow step 3\")\n",
    "\n",
    "While one major advantage of ML approaches is that they are robust when the number of features is very large, there are cases where removing unuseful features or selecting only the best features may help you better answer your question. One common issue we see with using feature selection for machine learning is using the whole dataset to select the best features, which results in overfitting! **Be sure you specify your test set so that this data is not used for feature selection!**\n",
    "\n",
    "\n",
    "### Automated feature selection: Feature_Selection.py\n",
    "\n",
    "Input\n",
    "```\n",
    "-df: your data table\n",
    "-test: what instances to hold out (i.e. test instances!)\n",
    "-cl_train: labels to include in training the feature selection algorithm\n",
    "-type: (c) classification or (r) regression\n",
    "-alg: what feature selection algorithm to use (e.g. lasso, elastic net, random forest)\n",
    "-p: Parameter specific to different algorithms (use -h for more information)\n",
    "-n: Number of feature to select (unless algorithm does this automatically)\n",
    "-save: save name for list of selected features\n",
    "```\n",
    "\n",
    "\n",
    "Here we will use one of the most common feature selection algorithms: LASSO. LASSO requires the user to select the level of sparcity (-p) they want to induce during feature selection, where a larger value will result in more features being selected and a smaller value resulting in fewer features being selected. You can play around with this value to see what it does for your data.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing testldout instances...\n",
      "Dropping instances that are not in ['special', 'gen'], changed dimensions from (2587, 566) to (2565, 566) (instance, features).\n",
      "\n",
      "Snapshot of data:\n",
      "              Class  Crubella_183_v1.0.csv  FamilySize  Transferase  \\\n",
      "YP_008563134      0                    0.0    0.010582          0.0   \n",
      "XP_010327628      0                    0.0    0.000000          0.0   \n",
      "XP_010327578      0                    0.0    0.015873          0.0   \n",
      "XP_010327494      0                    1.0    0.021164          0.0   \n",
      "YP_008563119      1                    0.0    0.000000          0.0   \n",
      "YP_008563115      0                    0.0    0.010582          0.0   \n",
      "\n",
      "              Exo_endo_phos  \n",
      "YP_008563134            0.0  \n",
      "XP_010327628            0.0  \n",
      "XP_010327578            0.0  \n",
      "XP_010327494            0.0  \n",
      "YP_008563119            0.0  \n",
      "YP_008563115            0.0  \n",
      "=====* Running L1/LASSO based feature selection *=====\n",
      "Features selected using LASSO: ['p450' 'UDPGT' 'tandemDupGenes' 'Nicotiana_tabacum.TN90_AYMY.SS.csv'\n",
      " 'Ppatens_318_v3.3.csv' 'Atrichopoda_291_v1.0.csv' 'Coffea_canephora.csv'\n",
      " 'Nicotiana_tomen.csv' 'BrapaFPsc_277_v1.3.csv' 'FamilySize_cat_small']\n",
      "\n",
      "Number of features selected using LASSO (sparcity parameter = 0.01): 10\n",
      "Run time (sec):0.33\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%run ../Feature_Selection.py -df data_mod.txt \\\n",
    "                            -test test_genes.txt \\\n",
    "                            -cl_train special,gen  \\\n",
    "                            -type c  \\\n",
    "                            -alg lasso  \\\n",
    "                            -p 0.01  \\\n",
    "                            -save top_feat_lasso.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing testldout instances...\n",
      "Dropping instances that are not in ['special', 'gen'], changed dimensions from (2587, 566) to (2565, 566) (instance, features).\n",
      "\n",
      "Snapshot of data:\n",
      "              Class  Crubella_183_v1.0.csv  FamilySize  Transferase  \\\n",
      "YP_008563134      0                    0.0    0.010582          0.0   \n",
      "XP_010327628      0                    0.0    0.000000          0.0   \n",
      "XP_010327620      1                    0.0    0.052910          0.0   \n",
      "XP_010327578      0                    0.0    0.015873          0.0   \n",
      "XP_010327494      0                    1.0    0.021164          0.0   \n",
      "YP_008563115      0                    0.0    0.010582          0.0   \n",
      "\n",
      "              Exo_endo_phos  \n",
      "YP_008563134            0.0  \n",
      "XP_010327628            0.0  \n",
      "XP_010327620            0.0  \n",
      "XP_010327578            0.0  \n",
      "XP_010327494            0.0  \n",
      "YP_008563115            0.0  \n",
      "Run time (sec):0.28\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%run ../Feature_Selection.py -df data_mod.txt  \\\n",
    "                            -test test_genes.txt  \\\n",
    "                            -cl_train special,gen \\\n",
    "                            -type c  \\\n",
    "                            -alg random  \\\n",
    "                            -n 10  \\\n",
    "                            -save rand_feat.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "![Step 4](../_img/step4.png \"ML Workflow step 4\")\n",
    "\n",
    "Next we want to determine which ML algorithm (i.e. Support Vector Machine (SVM), Random Forest (RF)) we should use and what parameters needed by those algorithms work best. Importantly, at this stage we **only assess our model performance on the validation data** in order to assure we aren't just selecting the algorithm that works best on our held out testing data. The pipeline will automatically withhold the testing data from the parameter selection (i.e. grid search) step. \n",
    "\n",
    "Note, the pipeline **automatically \"balances\" your data**, meaning it pulls the same number of instances of each class for training. This avoids biasing the model to just predict everything as the more common class. This is a major reason why we want to run multiple replicates of the model!\n",
    "\n",
    "\n",
    "### Algorithm Selection\n",
    "The machine learning algorithms in the ML_Pipeline are implement from [SciKit-Learn](https://scikit-learn.org/stable/), which has excellent resources to learn more about the ins and outs of these algorithms.\n",
    "\n",
    "**Why is algorithm selection useful?** ML models are able to learn patterns from data without the being explictely programmed to look for those patterns. ML algorithms differ in what patterns they excel at finding. For example, SVM is limited to linear relationships between feature and labels, while RF, because of its heiarchical structure, is able to model interactive patterns between your features. Furthermore, algorithms vary in their complexity and the amount of training data that is needed in order to  \n",
    "\n",
    "\n",
    "### Parameter Selection\n",
    "Most ML algorithms have internal parameters that need to be set by the user. For example:\n",
    "\n",
    "![RF Parameter examples](../_img/rf_params.png \"Sample of RF parameters\")\n",
    "\n",
    "\n",
    "There are two general strategies for parameter selection: the grid search (default option: left) and the random search (use \"-gs_type random\": right):\n",
    "![Grid search](../_img/grid_rand_search.png \"Grid Search\")\n",
    "*Image: Bergstra & Bengio 2012; used under CC-BY license*\n",
    "\n",
    "\n",
    "### Training and Validation\n",
    "Training and validation is done using a [cross-validation (CV)](https://towardsdatascience.com/cross-validation-70289113a072) scheme. CV is useful because it makes good use of our data (i.e. uses all non-test data for training at some point) but also makes sure we are selecting the best parameters/algorithms on models that aren't overfit to the training data. Here is a visual to demonstrate how CV works (with 10-cv folds in this example):\n",
    "\n",
    "![Cross Validation](../_img/cross_validation.png \"Cross validation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated parameter selection, ML training, validation, & testing:  ML_classification.py/ML_regression.py\n",
    "\n",
    "**Input:**\n",
    "```\n",
    "-df: your data table\n",
    "-test: what instances to hold out (i.e. test instances)\n",
    "-cl_train: labels to include in training the feature selection algorithm\n",
    "-alg: what ML algorithm to use (e.g. SVM, RF, LogReg)\n",
    "-cv: Number of cross-validation folds (default = 10, use fewer if data set is small)\n",
    "-n: Number of replicates of the cross-validation scheme to run (default = 100)\n",
    "```\n",
    "\n",
    "*There are many functions available within the pipeline that are not described in this workshop. For more options run:*\n",
    "```\n",
    "python ML_classification.py -h\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing test instances to apply model on later...\n",
      "Snapshot of data being used:\n",
      "                Class  Crubella_183_v1.0.csv  FamilySize  Transferase  \\\n",
      "YP_008563134      gen                    0.0    0.016667          0.0   \n",
      "XP_010327628      gen                    0.0    0.000000          0.0   \n",
      "XP_010327620  special                    0.0    0.083333          0.0   \n",
      "XP_010327578      gen                    0.0    0.025000          0.0   \n",
      "XP_010327494      gen                    1.0    0.033333          0.0   \n",
      "\n",
      "              Exo_endo_phos  \n",
      "YP_008563134            0.0  \n",
      "XP_010327628            0.0  \n",
      "XP_010327620            0.0  \n",
      "XP_010327578            0.0  \n",
      "XP_010327494            0.0  \n",
      "\n",
      "\n",
      "CLASSES: ['gen' 'special']\n",
      "POS: special type:  <class 'str'>\n",
      "NEG: gen type:  <class 'str'>\n",
      "\n",
      "Balanced dataset will include 478 instances of each class\n",
      "\n",
      "\n",
      "===>  Grid search started  <===\n",
      "Round 1 of 10\n",
      "Round 2 of 10\n",
      "Round 3 of 10\n",
      "Round 4 of 10\n",
      "Round 5 of 10\n",
      "Round 6 of 10\n",
      "Round 7 of 10\n",
      "Round 8 of 10\n",
      "Round 9 of 10\n",
      "Round 10 of 10\n",
      "Parameter sweep time: 20.410971 seconds\n",
      "Parameters selected: Kernel=Linear, C=0.5\n",
      "Grid search complete. Time: 20.441754 seconds\n",
      "\n",
      "\n",
      "===>  ML Pipeline started  <===\n",
      "  Round 1 of 10\n",
      "  Round 2 of 10\n",
      "  Round 3 of 10\n",
      "  Round 4 of 10\n",
      "  Round 5 of 10\n",
      "  Round 6 of 10\n",
      "  Round 7 of 10\n",
      "  Round 8 of 10\n",
      "  Round 9 of 10\n",
      "  Round 10 of 10\n",
      "ML Pipeline time: 11.699244 seconds\n",
      "\n",
      "\n",
      "===>  ML Results  <===\n",
      "\n",
      "Validation Set Scores\n",
      "Accuracy: 0.843828 (+/- stdev 0.005862)\n",
      "F1: 0.848847 (+/- stdev 0.005386)\n",
      "AUC-ROC: 0.908589 (+/- stdev 0.004616)\n",
      "AUC-PRC: 0.905385 (+/- stdev 0.008574)\n",
      "\n",
      "\n",
      "Test Set Scores:\n",
      "Precision: 0.823875\n",
      "Accuracy: 0.846234\n",
      "F1: 0.851365\n",
      "AUC-ROC: 0.931953 (+/- stdev 0.004301)\n",
      "AUC-PRC: 0.855205 (+/- stdev 0.011839)\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "%run ../ML_classification.py -df data_mod.txt \\\n",
    "                        -test test_genes.txt \\\n",
    "                        -cl_train special,gen \\\n",
    "                        -alg SVM \\\n",
    "                        -cv 5 \\\n",
    "                        -n 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results Breakdown\n",
    "\n",
    "There are dozens of [performance metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) that can be used to assess how well a ML model works. While the best metric for you depends on the type of question you are asking, some of the most generally useful metrics include the area under the Receiver Operator Characteristic curve (AUC-ROC), the area under the Precision-Recall curve (AUC_PRc), and the F-measure (F1).\n",
    "\n",
    "![AUCROC_Correlation](../_img/metrics.png \"AUCROC Correlation\")\n",
    "\n",
    "\n",
    "Running the same script (only changing **-alg XXX**), average performance on the validation data using other algorithms:\n",
    "\n",
    "| Alg  \t| F1  \t| AUC-ROC  \t|\n",
    "|---\t|---\t|---\t|\n",
    "| RF  \t| 0.787  \t| 0.824  \t|\n",
    "| LogReg  \t| 0.862  \t| 0.921  \t|\n",
    "| SVMpoly  \t| 0.833  \t| 0.897  \t|\n",
    "| SVMrbf  \t| 0.855  \t| 0.905  \t|\n",
    "| SVM  \t| 0.856  \t| 0.911  \t|\n",
    "\n",
    "\n",
    "***SVM performed best on the validation data so we will continue with that algorithm!***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Step 5](../_img/step5.png \"ML Workflow step 5\")\n",
    "\n",
    "Now that we have our best performing algorithm, we will run the pipeline one more time, but with more replicates (note, I still just use 10 here for time!) and we will use it to predict our unknown genes. \n",
    "\n",
    "**Additional input:**\n",
    "```\n",
    "- apply: List of lable names to apply trained model to (i.e. all, or 'unknown')\n",
    "- plots: True/False if you want the pipeline to generate performance metric plots (default = F)\n",
    "- save: Name to save output to (will over-write old files)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing test instances to apply model on later...\n",
      "Snapshot of data being used:\n",
      "                Class  Crubella_183_v1.0.csv  FamilySize  Transferase  \\\n",
      "YP_008563134      gen                    0.0    0.016667          0.0   \n",
      "XP_010327628      gen                    0.0    0.000000          0.0   \n",
      "XP_010327620  special                    0.0    0.083333          0.0   \n",
      "XP_010327578      gen                    0.0    0.025000          0.0   \n",
      "XP_010327494      gen                    1.0    0.033333          0.0   \n",
      "\n",
      "              Exo_endo_phos  \n",
      "YP_008563134            0.0  \n",
      "XP_010327628            0.0  \n",
      "XP_010327620            0.0  \n",
      "XP_010327578            0.0  \n",
      "XP_010327494            0.0  \n",
      "\n",
      "\n",
      "CLASSES: ['gen' 'special']\n",
      "POS: special type:  <class 'str'>\n",
      "NEG: gen type:  <class 'str'>\n",
      "\n",
      "Balanced dataset will include 478 instances of each class\n",
      "\n",
      "\n",
      "===>  Grid search started  <===\n",
      "Round 1 of 10\n",
      "Round 2 of 10\n",
      "Round 3 of 10\n",
      "Round 4 of 10\n",
      "Round 5 of 10\n",
      "Round 6 of 10\n",
      "Round 7 of 10\n",
      "Round 8 of 10\n",
      "Round 9 of 10\n",
      "Round 10 of 10\n",
      "Parameter sweep time: 20.472088 seconds\n",
      "Parameters selected: Kernel=Linear, C=0.5\n",
      "Grid search complete. Time: 20.474511 seconds\n",
      "\n",
      "\n",
      "===>  ML Pipeline started  <===\n",
      "  Round 1 of 10\n",
      "  Round 2 of 10\n",
      "  Round 3 of 10\n",
      "  Round 4 of 10\n",
      "  Round 5 of 10\n",
      "  Round 6 of 10\n",
      "  Round 7 of 10\n",
      "  Round 8 of 10\n",
      "  Round 9 of 10\n",
      "  Round 10 of 10\n",
      "ML Pipeline time: 10.208670 seconds\n",
      "\n",
      "Generating ROC & PR curves\n",
      "\n",
      "\n",
      "===>  ML Results  <===\n",
      "\n",
      "Validation Set Scores\n",
      "Accuracy: 0.843828 (+/- stdev 0.005862)\n",
      "F1: 0.848847 (+/- stdev 0.005386)\n",
      "AUC-ROC: 0.908589 (+/- stdev 0.004616)\n",
      "AUC-PRC: 0.905385 (+/- stdev 0.008574)\n",
      "\n",
      "\n",
      "Test Set Scores:\n",
      "Precision: 0.823875\n",
      "Accuracy: 0.846234\n",
      "F1: 0.851365\n",
      "AUC-ROC: 0.931953 (+/- stdev 0.004301)\n",
      "AUC-PRC: 0.855205 (+/- stdev 0.011839)\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "%run ../ML_classification.py -df data_mod.txt \\\n",
    "                            -test test_genes.txt \\\n",
    "                            -cl_train special,gen \\\n",
    "                            -alg SVM \\\n",
    "                            -cv 5 \\\n",
    "                            -n 10 \\\n",
    "                            -apply unknown \\\n",
    "                            -plots T \\\n",
    "                            -save metab_SVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check out our results...**\n",
    "\n",
    "Here are the files that are output from the model:\n",
    "- **data.txt_results:** A detailed look at the model that was run and its performance.  \n",
    "\n",
    "- **data.txt_scores:** The probability score for each gene (i.e. how confidently it was predicted) and the final classification for each gene, including the unknowns the model was applied to.\n",
    "\n",
    "- **data.txt_imp:** The importance of each feature in your model.\n",
    "\n",
    "- **data.txt_GridSearch:** Detailed results from the parameter grid search.\n",
    "\n",
    "- **data.txt_BalancedID:** A list of the genes that were included in each replicate after downsampling to balance the model.\n",
    "\n",
    "*For a detailed description of the content of the pipeline output see the [README](../README.md)*\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if we use fewer features?\n",
    "\n",
    "Additional input:\n",
    "```\n",
    "- feat: List of features to use.\n",
    "```\n",
    "Use smaller balenced data set\n",
    "\n",
    "### Advanced Topics\n",
    "- multiclass\n",
    "- transfer learning\n",
    "- venn diagrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using subset of features from: top_feat_lasso.txt\n",
      "Removing test instances to apply model on later...\n",
      "Snapshot of data being used:\n",
      "                Class  p450  UDPGT  tandemDupGenes  \\\n",
      "YP_008563134      gen   0.0    0.0             0.0   \n",
      "XP_010327628      gen   0.0    0.0             0.0   \n",
      "XP_010327620  special   0.0    0.0             0.0   \n",
      "XP_010327578      gen   0.0    0.0             0.0   \n",
      "XP_010327494      gen   0.0    0.0             0.0   \n",
      "\n",
      "              Nicotiana_tabacum.TN90_AYMY.SS.csv  \n",
      "YP_008563134                                 0.0  \n",
      "XP_010327628                                 0.0  \n",
      "XP_010327620                                 0.0  \n",
      "XP_010327578                                 0.0  \n",
      "XP_010327494                                 1.0  \n",
      "\n",
      "\n",
      "CLASSES: ['gen' 'special']\n",
      "POS: special type:  <class 'str'>\n",
      "NEG: gen type:  <class 'str'>\n",
      "\n",
      "Balanced dataset will include 478 instances of each class\n",
      "\n",
      "\n",
      "===>  Grid search started  <===\n",
      "Round 1 of 10\n",
      "Round 2 of 10\n",
      "Round 3 of 10\n",
      "Round 4 of 10\n",
      "Round 5 of 10\n",
      "Round 6 of 10\n",
      "Round 7 of 10\n",
      "Round 8 of 10\n",
      "Round 9 of 10\n",
      "Round 10 of 10\n",
      "Parameter sweep time: 6.755940 seconds\n",
      "Parameters selected: Kernel=Linear, C=0.5\n",
      "Grid search complete. Time: 6.757552 seconds\n",
      "\n",
      "\n",
      "===>  ML Pipeline started  <===\n",
      "  Round 1 of 10\n",
      "  Round 2 of 10\n",
      "  Round 3 of 10\n",
      "  Round 4 of 10\n",
      "  Round 5 of 10\n",
      "  Round 6 of 10\n",
      "  Round 7 of 10\n",
      "  Round 8 of 10\n",
      "  Round 9 of 10\n",
      "  Round 10 of 10\n",
      "ML Pipeline time: 4.051459 seconds\n",
      "\n",
      "\n",
      "===>  ML Results  <===\n",
      "\n",
      "Validation Set Scores\n",
      "Accuracy: 0.635356 (+/- stdev 0.016613)\n",
      "F1: 0.703515 (+/- stdev 0.009513)\n",
      "AUC-ROC: 0.736579 (+/- stdev 0.009872)\n",
      "AUC-PRC: 0.736462 (+/- stdev 0.011852)\n",
      "\n",
      "\n",
      "Test Set Scores:\n",
      "Precision: 0.599419\n",
      "Accuracy: 0.643305\n",
      "F1: 0.707798\n",
      "AUC-ROC: 0.700146 (+/- stdev 0.007866)\n",
      "AUC-PRC: 0.382885 (+/- stdev 0.015616)\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "%run ../ML_classification.py -df data_mod.txt \\\n",
    "                            -test test_genes.txt \\\n",
    "                            -cl_train special,gen \\\n",
    "                            -alg SVM \\\n",
    "                            -cv 5 \\\n",
    "                            -n 10 \\\n",
    "                            -feat top_feat_lasso.txt \\\n",
    "                            -save metab_SVM_lasso10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using subset of features from: rand_feat.txt_10\n",
      "Removing test instances to apply model on later...\n",
      "Snapshot of data being used:\n",
      "                Class  Osativa_medKaKs  Glyco_hydro_28  NIR_SIR  \\\n",
      "YP_008563134      gen         0.247338             0.0      0.0   \n",
      "XP_010327628      gen         0.247338             0.0      0.0   \n",
      "XP_010327620  special         0.206369             0.0      0.0   \n",
      "XP_010327578      gen         0.212135             0.0      0.0   \n",
      "XP_010327494      gen         0.179797             0.0      0.0   \n",
      "\n",
      "              GHMP_kinases_N  \n",
      "YP_008563134             0.0  \n",
      "XP_010327628             0.0  \n",
      "XP_010327620             0.0  \n",
      "XP_010327578             0.0  \n",
      "XP_010327494             0.0  \n",
      "\n",
      "\n",
      "CLASSES: ['gen' 'special']\n",
      "POS: special type:  <class 'str'>\n",
      "NEG: gen type:  <class 'str'>\n",
      "\n",
      "Balanced dataset will include 478 instances of each class\n",
      "\n",
      "\n",
      "===>  Grid search started  <===\n",
      "Round 1 of 10\n",
      "Round 2 of 10\n",
      "Round 3 of 10\n",
      "Round 4 of 10\n",
      "Round 5 of 10\n",
      "Round 6 of 10\n",
      "Round 7 of 10\n",
      "Round 8 of 10\n",
      "Round 9 of 10\n",
      "Round 10 of 10\n",
      "Parameter sweep time: 5.437438 seconds\n",
      "Parameters selected: Kernel=Linear, C=50.0\n",
      "Grid search complete. Time: 5.439099 seconds\n",
      "\n",
      "\n",
      "===>  ML Pipeline started  <===\n",
      "  Round 1 of 10\n",
      "  Round 2 of 10\n",
      "  Round 3 of 10\n",
      "  Round 4 of 10\n",
      "  Round 5 of 10\n",
      "  Round 6 of 10\n",
      "  Round 7 of 10\n",
      "  Round 8 of 10\n",
      "  Round 9 of 10\n",
      "  Round 10 of 10\n",
      "ML Pipeline time: 9.045218 seconds\n",
      "\n",
      "\n",
      "===>  ML Results  <===\n",
      "\n",
      "Validation Set Scores\n",
      "Accuracy: 0.611925 (+/- stdev 0.021897)\n",
      "F1: 0.696840 (+/- stdev 0.009461)\n",
      "AUC-ROC: 0.655158 (+/- stdev 0.014269)\n",
      "AUC-PRC: 0.587776 (+/- stdev 0.013489)\n",
      "\n",
      "\n",
      "Test Set Scores:\n",
      "Precision: 0.541878\n",
      "Accuracy: 0.569038\n",
      "F1: 0.674566\n",
      "AUC-ROC: 0.639915 (+/- stdev 0.001819)\n",
      "AUC-PRC: 0.265566 (+/- stdev 0.000393)\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "%run ../ML_classification.py -df data_mod.txt \\\n",
    "                            -test test_genes.txt \\\n",
    "                            -cl_train special,gen \\\n",
    "                            -alg SVM \\\n",
    "                            -cv 5 \\\n",
    "                            -n 10 \\\n",
    "                            -feat rand_feat.txt_10 \\\n",
    "                            -save metab_SVM_rand10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Your Results\n",
    "\n",
    "There are a number of vizualization tools available in the ML-Pipeline (see ML_Postprocessing). Here we will use ML_plots. \n",
    "\n",
    "\n",
    "**ML_plots.py input:**\n",
    "```\n",
    "ML_plots.py [SAVE_NAME] [POS] [NEG] [M1_name] [PATH_M1_scores] [M2_name] [PATH_M2_scores]... [Mn_name] [PATH_Mn_scores]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\n",
      "LASSO\n",
      "Random\n",
      "                Class      Mean     stdev Predicted_0.43    Median   score_0  \\\n",
      "ID                                                                             \n",
      "NP_001233775  special  0.879745  0.046322        special  0.887030  0.837215   \n",
      "NP_001233777      gen  0.297954  0.103856            gen  0.272025  0.294006   \n",
      "NP_001233790  special  0.465117  0.104629        special  0.474427  0.338578   \n",
      "NP_001233795      gen  0.127774  0.051437            gen  0.113469  0.115227   \n",
      "NP_001233801      gen  0.143935  0.042301            gen  0.147364  0.075589   \n",
      "\n",
      "               score_1   score_2   score_3   score_4   score_5   score_6  \\\n",
      "ID                                                                         \n",
      "NP_001233775  0.903283  0.812769  0.878187  0.841674  0.928159  0.895872   \n",
      "NP_001233777  0.151053  0.479233  0.281056  0.262994  0.234144  0.231677   \n",
      "NP_001233790  0.314705  0.575976  0.379030  0.537606  0.543523  0.429752   \n",
      "NP_001233795  0.109948  0.111711  0.122113  0.260511  0.074159  0.160996   \n",
      "NP_001233801  0.163111  0.121436  0.090758  0.178118  0.131618  0.163468   \n",
      "\n",
      "               score_7   score_8   score_9  \n",
      "ID                                          \n",
      "NP_001233775  0.961288  0.897323  0.841679  \n",
      "NP_001233777  0.221143  0.430542  0.393694  \n",
      "NP_001233790  0.609417  0.519101  0.403485  \n",
      "NP_001233795  0.105564  0.097981  0.119534  \n",
      "NP_001233801  0.209195  0.181365  0.124694  \n",
      "Working on all 0\n",
      "Working on all 1\n",
      "Working on all 2\n",
      "Working on all 3\n",
      "Working on all 4\n",
      "Working on all 5\n",
      "Working on all 6\n",
      "Working on all 7\n",
      "Working on all 8\n",
      "Working on all 9\n",
      "                Class      Mean     stdev Predicted_0.35    Median   score_0  \\\n",
      "ID                                                                             \n",
      "NP_001233775  special  0.383419  0.027725        special  0.381591  0.359985   \n",
      "NP_001233777      gen  0.465532  0.017606        special  0.465559  0.482258   \n",
      "NP_001233790  special  0.716291  0.024946        special  0.714932  0.740072   \n",
      "NP_001233795      gen  0.751087  0.019363        special  0.749701  0.777267   \n",
      "NP_001233801      gen  0.585085  0.029517        special  0.589643  0.613328   \n",
      "\n",
      "               score_1   score_2   score_3   score_4   score_5   score_6  \\\n",
      "ID                                                                         \n",
      "NP_001233775  0.367296  0.350076  0.385260  0.377923  0.398557  0.405146   \n",
      "NP_001233777  0.473783  0.468375  0.439548  0.500248  0.451350  0.462743   \n",
      "NP_001233790  0.700554  0.713647  0.679693  0.696488  0.729305  0.716218   \n",
      "NP_001233795  0.760992  0.742709  0.717229  0.727620  0.772474  0.744830   \n",
      "NP_001233801  0.599802  0.535209  0.530347  0.588076  0.612635  0.608152   \n",
      "\n",
      "               score_7   score_8   score_9  \n",
      "ID                                          \n",
      "NP_001233775  0.405845  0.434538  0.349562  \n",
      "NP_001233777  0.457922  0.449175  0.469918  \n",
      "NP_001233790  0.748537  0.689007  0.749385  \n",
      "NP_001233795  0.753255  0.746148  0.768345  \n",
      "NP_001233801  0.589336  0.589950  0.584013  \n",
      "Working on LASSO 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on LASSO 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on LASSO 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on LASSO 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on LASSO 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on LASSO 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on LASSO 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on LASSO 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on LASSO 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on LASSO 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Class      Mean     stdev Predicted_0.42    Median   score_0  \\\n",
      "ID                                                                             \n",
      "NP_001233775  special  0.537257  0.008205        special  0.537263  0.537502   \n",
      "NP_001233777      gen  0.536167  0.006922        special  0.537263  0.537502   \n",
      "NP_001233790  special  0.529128  0.005849        special  0.527949  0.526287   \n",
      "NP_001233795      gen  0.087656  0.018650            gen  0.090657  0.096085   \n",
      "NP_001233801      gen  0.320816  0.031036            gen  0.323903  0.308653   \n",
      "\n",
      "               score_1   score_2   score_3   score_4   score_5   score_6  \\\n",
      "ID                                                                         \n",
      "NP_001233775  0.526561  0.550286  0.541096  0.534715  0.547085  0.530501   \n",
      "NP_001233777  0.526561  0.539483  0.541096  0.534715  0.547085  0.530501   \n",
      "NP_001233790  0.524323  0.539483  0.531433  0.529611  0.535850  0.520343   \n",
      "NP_001233795  0.087057  0.096370  0.096426  0.094257  0.082932  0.068913   \n",
      "NP_001233801  0.346226  0.286308  0.306138  0.330397  0.264703  0.347611   \n",
      "\n",
      "               score_7   score_8   score_9  \n",
      "ID                                          \n",
      "NP_001233775  0.542133  0.537023  0.525666  \n",
      "NP_001233777  0.542133  0.537023  0.525576  \n",
      "NP_001233790  0.532992  0.525383  0.525576  \n",
      "NP_001233795  0.048700  0.087009  0.118814  \n",
      "NP_001233801  0.319355  0.328451  0.370317  \n",
      "Working on Random 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Random 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Random 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Random 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Random 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Random 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Random 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Random 7\n",
      "Working on Random 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Random 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n",
      "/Users/cbazodi/Documents/GitHub/ML-Pipeline/scripts_PostAnalysis/ML_plots.py:82: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precis.append(TP/(TP+FP))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%run ../scripts_PostAnalysis/ML_plots.py compare_SVM special gen all metab_SVM_scores.txt LASSO metab_SVM_lasso10_scores.txt Random metab_SVM_rand10_scores.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model All, replicate 0\n",
      "Processing model All, replicate 1\n",
      "Processing model All, replicate 2\n",
      "Processing model All, replicate 3\n",
      "Processing model All, replicate 4\n",
      "Processing model All, replicate 5\n",
      "Processing model All, replicate 6\n",
      "Processing model All, replicate 7\n",
      "Processing model All, replicate 8\n",
      "Processing model All, replicate 9\n",
      "Processing model LASSO, replicate 0\n",
      "Processing model LASSO, replicate 1\n",
      "Processing model LASSO, replicate 2\n",
      "Processing model LASSO, replicate 3\n",
      "Processing model LASSO, replicate 4\n",
      "Processing model LASSO, replicate 5\n",
      "Processing model LASSO, replicate 6\n",
      "Processing model LASSO, replicate 7\n",
      "Processing model LASSO, replicate 8\n",
      "Processing model LASSO, replicate 9\n",
      "Processing model Random, replicate 0\n",
      "Processing model Random, replicate 1\n",
      "Processing model Random, replicate 2\n",
      "Processing model Random, replicate 3\n",
      "Processing model Random, replicate 4\n",
      "Processing model Random, replicate 5\n",
      "Processing model Random, replicate 6\n",
      "Processing model Random, replicate 7\n",
      "Processing model Random, replicate 8\n",
      "Processing model Random, replicate 9\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%run ../scripts_PostAnalysis/ML_plots.py -save compare_SVM \\\n",
    "                    -cl_train special gen \\\n",
    "                    -names All LASSO Random\\\n",
    "                    -scores metab_SVM_scores.txt metab_SVM_lasso10_scores.txt metab_SVM_rand10_scores.txt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
